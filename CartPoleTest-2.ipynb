{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of episode :20, avg score : 10.4, buffer size : 208, epsilon : 7.9%\n",
      "# of episode :40, avg score : 9.5, buffer size : 398, epsilon : 7.8%\n",
      "# of episode :60, avg score : 10.6, buffer size : 609, epsilon : 7.7%\n",
      "# of episode :80, avg score : 9.4, buffer size : 797, epsilon : 7.6%\n",
      "# of episode :100, avg score : 9.6, buffer size : 988, epsilon : 7.5%\n",
      "# of episode :120, avg score : 9.7, buffer size : 1182, epsilon : 7.4%\n",
      "# of episode :140, avg score : 10.1, buffer size : 1383, epsilon : 7.3%\n",
      "# of episode :160, avg score : 10.3, buffer size : 1589, epsilon : 7.2%\n",
      "# of episode :180, avg score : 9.9, buffer size : 1787, epsilon : 7.1%\n",
      "# of episode :200, avg score : 9.8, buffer size : 1984, epsilon : 7.0%\n",
      "# of episode :220, avg score : 9.2, buffer size : 2169, epsilon : 6.9%\n",
      "# of episode :240, avg score : 9.8, buffer size : 2365, epsilon : 6.8%\n",
      "# of episode :260, avg score : 9.6, buffer size : 2556, epsilon : 6.7%\n",
      "# of episode :280, avg score : 10.3, buffer size : 2762, epsilon : 6.6%\n",
      "# of episode :300, avg score : 9.8, buffer size : 2957, epsilon : 6.5%\n",
      "# of episode :320, avg score : 17.9, buffer size : 3316, epsilon : 6.4%\n",
      "# of episode :340, avg score : 24.1, buffer size : 3797, epsilon : 6.3%\n",
      "# of episode :360, avg score : 26.5, buffer size : 4327, epsilon : 6.2%\n",
      "# of episode :380, avg score : 28.4, buffer size : 4895, epsilon : 6.1%\n",
      "# of episode :400, avg score : 32.8, buffer size : 5550, epsilon : 6.0%\n",
      "# of episode :420, avg score : 40.0, buffer size : 6349, epsilon : 5.9%\n",
      "# of episode :440, avg score : 79.1, buffer size : 7931, epsilon : 5.8%\n",
      "# of episode :460, avg score : 88.9, buffer size : 9709, epsilon : 5.7%\n",
      "# of episode :480, avg score : 127.5, buffer size : 12259, epsilon : 5.6%\n",
      "# of episode :500, avg score : 132.8, buffer size : 14915, epsilon : 5.5%\n",
      "# of episode :520, avg score : 143.2, buffer size : 17778, epsilon : 5.4%\n",
      "# of episode :540, avg score : 229.2, buffer size : 22362, epsilon : 5.3%\n",
      "# of episode :560, avg score : 148.4, buffer size : 25331, epsilon : 5.2%\n",
      "# of episode :580, avg score : 104.4, buffer size : 27419, epsilon : 5.1%\n",
      "# of episode :600, avg score : 95.1, buffer size : 29321, epsilon : 5.0%\n",
      "# of episode :620, avg score : 88.7, buffer size : 31094, epsilon : 4.9%\n",
      "# of episode :640, avg score : 117.2, buffer size : 33438, epsilon : 4.8%\n",
      "# of episode :660, avg score : 118.9, buffer size : 35816, epsilon : 4.7%\n",
      "# of episode :680, avg score : 162.8, buffer size : 39071, epsilon : 4.6%\n",
      "# of episode :700, avg score : 178.3, buffer size : 42638, epsilon : 4.5%\n",
      "# of episode :720, avg score : 217.1, buffer size : 46979, epsilon : 4.4%\n",
      "# of episode :740, avg score : 233.6, buffer size : 50000, epsilon : 4.3%\n",
      "# of episode :760, avg score : 284.9, buffer size : 50000, epsilon : 4.2%\n",
      "# of episode :780, avg score : 293.9, buffer size : 50000, epsilon : 4.1%\n",
      "# of episode :800, avg score : 235.3, buffer size : 50000, epsilon : 4.0%\n",
      "# of episode :820, avg score : 215.0, buffer size : 50000, epsilon : 3.9%\n",
      "# of episode :840, avg score : 213.9, buffer size : 50000, epsilon : 3.8%\n",
      "# of episode :860, avg score : 212.8, buffer size : 50000, epsilon : 3.7%\n",
      "# of episode :880, avg score : 215.9, buffer size : 50000, epsilon : 3.6%\n",
      "# of episode :900, avg score : 202.8, buffer size : 50000, epsilon : 3.5%\n",
      "# of episode :920, avg score : 204.4, buffer size : 50000, epsilon : 3.4%\n",
      "# of episode :940, avg score : 220.9, buffer size : 50000, epsilon : 3.3%\n",
      "# of episode :960, avg score : 240.2, buffer size : 50000, epsilon : 3.2%\n",
      "# of episode :980, avg score : 191.1, buffer size : 50000, epsilon : 3.1%\n",
      "Learning Completed\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import collections\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#Hyperparameters\n",
    "learning_rate = 0.0002\n",
    "gamma         = 0.98\n",
    "buffer_limit  = 50000\n",
    "batch_size    = 32\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "    \n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "    \n",
    "    def sample(self, n):\n",
    "        mini_batch = random.sample(self.buffer, n)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        \n",
    "        for transition in mini_batch:\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "\n",
    "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
    "               torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
    "               torch.tensor(done_mask_lst)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "class Qnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.fc1 = nn.Linear(4,256)\n",
    "        self.fc2 = nn.Linear(256,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "      \n",
    "    def sample_action(self, obs, epsilon):\n",
    "        out = self.forward(obs)\n",
    "        coin = random.random()\n",
    "        if coin < epsilon:\n",
    "            return random.randint(0,1)\n",
    "        else : \n",
    "            return out.argmax().item()\n",
    "            \n",
    "def train(q, q_target, memory, optimizer):\n",
    "    for i in range(10):\n",
    "        s,a,r,s_prime,done_mask = memory.sample(batch_size)\n",
    "\n",
    "        q_out = q(s)\n",
    "        q_a = q_out.gather(1,a)\n",
    "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
    "        target = r + gamma * max_q_prime * done_mask\n",
    "        loss = F.smooth_l1_loss(q_a, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "     \n",
    "        \n",
    "def main():\n",
    "    env = gym.make('CartPole-v1')\n",
    "    #env = gym.make('BeamRider-v0')\n",
    "    \n",
    "    q = Qnet()\n",
    "    q_target = Qnet()\n",
    "    q_target.load_state_dict(q.state_dict())\n",
    "    memory = ReplayBuffer()\n",
    "\n",
    "    print_interval = 20\n",
    "    score = 0.0  \n",
    "    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
    "\n",
    "    for n_epi in range(1000):\n",
    "        epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\n",
    "        s = env.reset()\n",
    "\n",
    "        for t in range(600):\n",
    "            a = q.sample_action(torch.from_numpy(s).float(), epsilon)      \n",
    "            s_prime, r, done, info = env.step(a)\n",
    "            done_mask = 0.0 if done else 1.0\n",
    "            memory.put((s,a,r/100.0,s_prime, done_mask))\n",
    "            s = s_prime\n",
    "\n",
    "            score += r\n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "        if memory.size()>2000:\n",
    "            train(q, q_target, memory, optimizer)\n",
    "\n",
    "        if n_epi%print_interval==0 and n_epi!=0:\n",
    "            q_target.load_state_dict(q.state_dict())\n",
    "            #env.render()\n",
    "            #plt.imshow(env.render(mode='rgb_array'))\n",
    "            print(\"# of episode :{}, avg score : {:.1f}, buffer size : {}, epsilon : {:.1f}%\".format(n_epi, score/print_interval, memory.size(), epsilon*100))\n",
    "            score = 0.0\n",
    "\n",
    "    print(\"Learning Completed\")\n",
    "    return q\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    q = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "for i_episode in range(5):\n",
    "    observation = env.reset()\n",
    "    for t in range(200):\n",
    "        env.render()\n",
    "        #print(observation)\n",
    "        #action = env.action_space.sample()\n",
    "        #action = q.sample_action(torch.from_numpy(observation).float(), 0)\n",
    "        action = q.sample_action(torch.from_numpy(observation).float(), max(0.01, 0.08 - 0.01*(t/200)))\n",
    "\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        #if done:\n",
    "        #  print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "        # break\n",
    "env.close()\n",
    "print(\"end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v1')\n",
    "frames = []\n",
    "\n",
    "for i_episode in range(5):\n",
    "    observation = env.reset()\n",
    "    for t in range(200):\n",
    "        #frames.append(env.render(mode = 'rgb_array'))\n",
    "        env.render()\n",
    "        #print(observation)\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        #if done:\n",
    "        #  print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "        # break\n",
    "\n",
    "env.close()\n",
    "#display_frames_as_gif(frames)\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The typical imports \n",
    "import gym \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "# Imports specifically so we can render outputs in Jupyter. \n",
    "from JSAnimation.IPython_display import display_animation \n",
    "from matplotlib import animation \n",
    "from IPython.display import display \n",
    "\n",
    "def display_frames_as_gif(frames): \n",
    "    \"\"\" Displays a list of frames as a gif, with controls \"\"\" \n",
    "    #plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72) \n",
    "    patch = plt.imshow(frames[0]) \n",
    "    plt.axis('off') \n",
    "    \n",
    "    def animate(i): \n",
    "        patch.set_data(frames[i]) \n",
    "        \n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50) \n",
    "    display(display_animation(anim, default_mode='loop'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
